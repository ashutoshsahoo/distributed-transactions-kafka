spring:
  application:
    name: order-service
  main:
    banner-mode: off
  kafka:
    bootstrap-servers: ${CK_ENDPOINT}
    properties:
      sasl.mechanism: PLAIN
      security.protocol: SASL_SSL
      sasl.jaas.config: org.apache.kafka.common.security.plain.PlainLoginModule required username='${CK_API_KEY}' password='${CK_API_SECRET}';
      # Required connection configs for Confluent Cloud Schema Registry
      basic.auth.credentials.source: USER_INFO
      basic.auth.user.info: ${CK_SR_API_KEY}:${CK_SR_API_SECRET}
      schema.registry.url: ${CK_SR_ENDPOINT}
      # use avro of specific type->order
      specific.avro.reader: true
    producer:
      key-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer

    streams:
      properties:
        default.key.serde: io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde
        default.value.serde: io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde
      state-dir: ./build/temp/kafka-streams/2
    admin:
      fail-fast: true
logging:
  pattern:
    level: "%5p [${spring.application.name:},%X{traceId:-},%X{spanId:-}]"
  level:
    root: warn
    com.ashu.practice: DEBUG
#    io.opentelemetry.exporters: TRACE
#    org.springframework.web.servlet.DispatcherServlet: DEBUG

management:
  metrics:
    enable:
      all: true
    distribution:
      percentiles-histogram:
        http:
          server:
            requests: true
        greeting:
          call: true
  tracing:
    enabled: true
    sampling:
      probability: 1.0
  endpoints:
    web:
      exposure:
        include: "*"
  zipkin:
    tracing:
      endpoint: http://localhost:9411/api/v2/spans